{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67fdf311",
   "metadata": {},
   "source": [
    "# Basic RAG Pipeline Implementation\n",
    "\n",
    "\n",
    "### Intro\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) pipeline using classes from src directory. The implementation is divided into individual pipeline stages:\n",
    "\n",
    "\n",
    "1. Document Processing: Token-aware chunking with overlap\n",
    "2. Embedding Generation: Semantic vectorization\n",
    "3. Vector Storage: PostgreSQL + pgvector indexing\n",
    "4. Retrieval: Cosine similarit*y search\n",
    "5. Generation: Context-augmented LLM completion\n",
    "\n",
    "### Components\n",
    "\n",
    "**TextProcessor** - Text segmentation and token budget management.\n",
    "\n",
    "* Token-based chunking (512 tokens, 50 token overlap)\n",
    "* Uses cl100k_base tokenizer for GPT compatibility\n",
    "* Adaptive context assembly within token budgets\n",
    "\n",
    "**HuggingFaceClient** - Embedding generation and LLM inference.\n",
    "\n",
    "* Embeddings: Local sentence-transformers (all-MiniLM-L6-v2, 384-dim)\n",
    "* Generation: Remote Hugging Face Inference API (default: Mistral-7B-Instruct)\n",
    "\n",
    "**PgVectorDB** - PostgreSQL interface with vector similarity search.\n",
    "\n",
    "* Stores embeddings as VECTOR(384) with chunk metadata\n",
    "* Uses ivfflat indexing for approximate nearest neighbor search\n",
    "* Cosine similarity search via <=> operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4d5c572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Optional\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# import psycopg2\n",
    "# from psycopg2.extras import execute_values, Json\n",
    "# from pgvector.psycopg2 import register_vector\n",
    "# from huggingface_hub import InferenceClient\n",
    "# from transformers import pipeline\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2dc959ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processor import TextProcessor\n",
    "from pgvector_client import PgVectorClient\n",
    "from hf_client import HuggingFaceClient\n",
    "# from rag_handler import PgVectorRAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c19e7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_CONN_STRING = os.getenv(\"PG_CONNECTION_STRING\")\n",
    "HF_TOKEN= os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "file_paths = [\n",
    "    \"../documents/policy.txt\",\n",
    "    \"../documents/basic_info.md\",\n",
    "    # Add more files\n",
    "]\n",
    "\n",
    "BATCH_SIZE=32 # batch_size=\n",
    "EMBEDDING_DIM=384 # embedding_dim\n",
    "\n",
    "CHUNK_SIZE=512\n",
    "CHUNK_OVERLAP=50\n",
    "MAX_CONTEXT_TOKENS=2000\n",
    "\n",
    "EMBEDDING_MODEL=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LLM_MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"# \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#  Query the system\n",
    "questions = [\n",
    "    \"What is mario's email?\",\n",
    "    \"How long does shipping take?\",\n",
    "    \"Where there any projects with recommendation systems done by Mario?\",\n",
    "    \"Does mario like data science?\"\n",
    "]\n",
    "\n",
    "\n",
    "SIMILARITY_THRESHOLD=0.2\n",
    "K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4d786ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pgvector_client:Database connected\n",
      "INFO:pgvector_client:pgvector extension enabled\n",
      "INFO:pgvector_client:Database schema created\n",
      "INFO:hf_client:Initialized embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:hf_client:Initialized LLM: mistralai/Mistral-7B-Instruct-v0.2\n"
     ]
    }
   ],
   "source": [
    "# Initialize components \n",
    "text_processor = TextProcessor(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    max_context_tokens=MAX_CONTEXT_TOKENS\n",
    ")\n",
    "\n",
    "db_client = PgVectorClient(\n",
    "    connection_string=PG_CONN_STRING,\n",
    "    embedding_dim=EMBEDDING_DIM  # Match embedding model output\n",
    ")\n",
    "\n",
    "hf_client = HuggingFaceClient(\n",
    "    hf_token=HF_TOKEN,\n",
    "    embedding_model=EMBEDDING_MODEL,\n",
    "    llm_model=LLM_MODEL,\n",
    "    # use_remote_llm=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a56b28",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f507f04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text_processor:Chunked policy.txt: 1 chunks\n",
      "INFO:__main__:Processed ../documents/policy.txt: 1 chunks\n",
      "INFO:__main__:chunk lengt 1, [{'content': 'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n', 'chunk_id': 0, 'token_count': 21, 'start_token': 0, 'end_token': 21, 'source': 'policy.txt'}]\n",
      "INFO:__main__:chunk lenght 1, [{'content': 'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n', 'chunk_id': 0, 'token_count': 21, 'start_token': 0, 'end_token': 21, 'source': 'policy.txt'}]\n",
      "INFO:__main__:total chunks: 1, [{'content': 'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n', 'chunk_id': 0, 'token_count': 21, 'start_token': 0, 'end_token': 21, 'source': 'policy.txt'}]\n",
      "INFO:text_processor:Chunked basic_info.md: 2 chunks\n",
      "INFO:__main__:Processed ../documents/basic_info.md: 2 chunks\n",
      "INFO:__main__:chunk lengt 2, [{'content': '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI', 'chunk_id': 0, 'token_count': 512, 'start_token': 0, 'end_token': 512, 'source': 'basic_info.md'}, {'content': ' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n', 'chunk_id': 1, 'token_count': 113, 'start_token': 462, 'end_token': 575, 'source': 'basic_info.md'}]\n",
      "INFO:__main__:chunk lenght 2, [{'content': '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI', 'chunk_id': 0, 'token_count': 512, 'start_token': 0, 'end_token': 512, 'source': 'basic_info.md'}, {'content': ' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n', 'chunk_id': 1, 'token_count': 113, 'start_token': 462, 'end_token': 575, 'source': 'basic_info.md'}]\n",
      "INFO:__main__:total chunks: 3, [{'content': 'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n', 'chunk_id': 0, 'token_count': 21, 'start_token': 0, 'end_token': 21, 'source': 'policy.txt'}, {'content': '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI', 'chunk_id': 0, 'token_count': 512, 'start_token': 0, 'end_token': 512, 'source': 'basic_info.md'}, {'content': ' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n', 'chunk_id': 1, 'token_count': 113, 'start_token': 462, 'end_token': 575, 'source': 'basic_info.md'}]\n",
      "INFO:__main__:Total chunks from all files: 3\n"
     ]
    }
   ],
   "source": [
    "all_chunks = [] # list of dicts. Each dict is a \n",
    "\n",
    "# Process each file\n",
    "for file_path in file_paths:\n",
    "    chunks = text_processor.chunk_file(file_path)\n",
    "    all_chunks.extend(chunks)\n",
    "    logger.info(f\"Processed {file_path}: {len(chunks)} chunks\")\n",
    "    logger.info(f\"chunk lengt {len(chunks)}, {chunks[:10]}\")\n",
    "    logger.info(f\"chunk lenght {len(chunks)}, {chunks[:10]}\")\n",
    "    logger.info(f\"total chunks: {len(all_chunks)}, {all_chunks[-10:]}\")\n",
    "\n",
    "logger.info(f\"Total chunks from all files: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffad1972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n',\n",
       " 'chunk_id': 0,\n",
       " 'token_count': 21,\n",
       " 'start_token': 0,\n",
       " 'end_token': 21,\n",
       " 'source': 'policy.txt'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf8d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 3 embeddings\n",
      "INFO:__main__:Generated embeddings for 3 chunks\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all chunks\n",
    "texts = [chunk['content'] for chunk in all_chunks]\n",
    "embeddings = hf_client.get_embeddings(texts)\n",
    "\n",
    "logger.info(f\"Generated embeddings for {len(embeddings)} chunks\")\n",
    "\n",
    "# Add embeddings to chunks\n",
    "for i, chunk in enumerate(all_chunks):\n",
    "    embedding = embeddings[i]\n",
    "    if hasattr(embedding, 'tolist'):\n",
    "        embedding = embedding.tolist()\n",
    "    chunk['embedding'] = embedding\n",
    "    # logger.info(f\"Generated embeddings for {len(embeddings)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa452f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert all chunks\n",
    "db_client.insert_chunks(all_chunks)\n",
    "logger.info(f\"Inserted {len(all_chunks)} chunks into database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae05a72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text_processor:Chunked policy.txt: 1 chunks\n",
      "INFO:text_processor:Chunked basic_info.md: 2 chunks\n"
     ]
    }
   ],
   "source": [
    "# chunks = []    \n",
    "# for file_path in file_paths:        \n",
    "#     try:            \n",
    "#         file_chunks = text_processor.chunk_file(file_path)            \n",
    "#         chunks.extend(file_chunks)        \n",
    "#     except Exception as e:            \n",
    "#         logger.error(f\"Failed to chunk {file_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75e9bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:chunk number 0, chunk len 2646: {'content': '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI', 'chunk_id': 0, 'token_count': 512, 'start_token': 0, 'end_token': 512, 'source': 'basic_info.md', 'embedding': [-0.10912732034921646, 0.043604664504528046, -0.026428064331412315, 0.06353767216205597, 0.05997278541326523, 0.08320455998182297, 0.024466723203659058, 0.04996594041585922, -0.06895292550325394, -0.08014482259750366, -0.07022880017757416, -0.031957291066646576, 0.03583429381251335, -0.025749927386641502, -0.012951596640050411, 0.02018999494612217, 0.029678357765078545, -0.04569322243332863, -0.06320782005786896, -0.05706409737467766, -0.04331180453300476, 0.02497866563498974, 0.052971526980400085, -0.0154264522716403, -0.06362714618444443, 0.04738915339112282, 0.04393313452601433, -0.004281361121684313, -0.07266434282064438, -0.04894518479704857, 0.0002380801015533507, 0.0005225560162216425, 0.04057130962610245, 0.028018444776535034, 0.015068694949150085, 0.03788794204592705, -0.03717321529984474, -0.006536061875522137, 0.022200867533683777, 0.035449616611003876, -0.025223804637789726, -0.10288682579994202, -0.07156573235988617, -0.0273739006370306, 0.10919729620218277, -0.061577245593070984, -0.01900104060769081, -0.0040129912085831165, -0.01124056801199913, 0.06137571856379509, -0.15827953815460205, -0.006794350687414408, -0.0023941544350236654, -0.024793975055217743, -0.028994571417570114, 0.078109510242939, -0.00971569586545229, -0.030210694298148155, 0.027779921889305115, -0.05987504497170448, 0.012838809750974178, -0.12923423945903778, -0.03581085428595543, -0.009582900442183018, -0.034077007323503494, -0.0147376274690032, -0.13259491324424744, 0.098941870033741, -0.10348133742809296, 0.003966064658015966, -0.010669359937310219, 0.00039385963464155793, -0.03820253908634186, 0.030194757506251335, -0.014312013052403927, 0.008484408259391785, -0.01378950010985136, 0.01607290282845497, 0.009311120957136154, -0.014613219536840916, 0.013019096106290817, 0.021824976429343224, -0.08861231058835983, 0.016337206587195396, -0.01936967670917511, -0.03846289590001106, 0.06118089333176613, -0.00384913245216012, -0.04562189429998398, 0.040658485144376755, 0.038305334746837616, 0.010570394806563854, 0.027279213070869446, -0.025562986731529236, -0.030283762142062187, 0.04587931931018829, 0.03789184242486954, -0.08420221507549286, 0.03911833092570305, 0.07658816128969193, 0.009519585408270359, 0.05282231792807579, 0.06914794445037842, 0.01998368836939335, -0.11218438297510147, -0.02922983653843403, -0.0419999323785305, 0.11114934086799622, -0.007108551450073719, -0.047231923788785934, -0.002540009096264839, 0.04152222350239754, -0.169357031583786, 0.0006640587816946208, 0.04285589978098869, -0.0068323551677167416, -0.07038658112287521, 0.0095657454803586, 0.03362094610929489, 0.0900745689868927, 0.04194601997733116, 0.09659568220376968, 0.0321674682199955, 0.05699388310313225, -0.03189663961529732, 0.008141875267028809, -0.057828933000564575, 8.998833902878845e-33, -0.05334220454096794, 0.0698375329375267, 0.02811334654688835, 0.08970962464809418, 0.05372180417180061, 0.0024877656251192093, -0.054978713393211365, 0.05060092359781265, -0.006374051794409752, 0.06493569910526276, -0.08223593235015869, 0.15358278155326843, 0.008201277814805508, 0.08553855121135712, -0.03525398299098015, 0.06453990936279297, -0.007518070284277201, 0.04551108926534653, -0.06466154754161835, -0.0246745515614748, 0.09109727293252945, 0.019940972328186035, -0.027676954865455627, 0.02466406300663948, 0.01280578225851059, 0.036149267107248306, 0.049040861427783966, 0.009369081817567348, 0.021225744858384132, 0.03499626740813255, 0.044213149696588516, -0.01700359769165516, 0.0043187979608774185, -0.03922662511467934, -0.00907813012599945, -0.015974201261997223, -0.08880233764648438, -0.12546001374721527, 0.005835319869220257, 0.02055293694138527, -0.09307359904050827, 0.050182096660137177, 0.011618492193520069, 0.023766588419675827, -0.10242156684398651, -0.0359809435904026, 0.07510560750961304, 0.018486974760890007, 0.06376917660236359, 0.009974388405680656, -0.054602984338998795, -0.10236991941928864, 0.04903329536318779, -0.011310538277029991, -0.0820407122373581, 0.009820823557674885, 0.03182581067085266, -0.021214239299297333, 0.002903138054534793, -0.06144231557846069, 0.035939011722803116, -0.007676535751670599, -0.03662596270442009, -0.09379604458808899, -0.041006918996572495, 0.011651788838207722, -0.01294238492846489, 0.038879845291376114, 0.10158826410770416, -0.051649753004312515, 0.02633967436850071, 0.04835664480924606, 0.07941407710313797, 0.04767008498311043, 0.09204687923192978, -0.014160355553030968, -0.020642470568418503, 0.052357111126184464, -0.04872554540634155, -0.019642503932118416, 0.06361602246761322, 0.013341442681849003, -0.034974731504917145, -0.03897206485271454, 0.03981255739927292, 0.07151836156845093, 0.060642972588539124, -0.04782669246196747, -0.04130670800805092, 0.0839260071516037, -0.08406735211610794, 0.0949857234954834, -0.008294488303363323, 0.07345675677061081, -0.059689365327358246, -9.35516664823139e-33, -0.0020285535138100386, 0.008917519822716713, 0.04043928161263466, -0.004655878525227308, 0.06771399080753326, 0.03433616831898689, -0.07844042032957077, -0.032139599323272705, 0.004581158049404621, -0.11368545144796371, -0.030043145641684532, -0.008874339051544666, 0.0018666359828785062, -0.010235605761408806, -0.03103133663535118, 0.0745500698685646, -0.034041136503219604, -0.009026451036334038, -0.09579918533563614, -0.04827944189310074, -0.10699671506881714, 0.039699945598840714, -0.0426509790122509, -0.009866947308182716, 0.013293576426804066, 0.0562816858291626, 0.009061678312718868, 0.016126438975334167, 0.0029305224306881428, 0.01676596701145172, -0.06584638357162476, -0.0038996536750346422, -0.10665837675333023, 0.005324734840542078, 0.011709608137607574, -0.0361107774078846, 0.004385451320558786, -0.08154536783695221, 0.015180404298007488, 0.07934203743934631, 0.06067494675517082, 0.026511352509260178, -0.03363615646958351, -0.028211606666445732, 0.0021748847793787718, 0.006837568711489439, 0.029886532574892044, -0.02882072515785694, 0.04749220982193947, -0.03288004547357559, -0.006518829148262739, 0.029001252725720406, -0.044213540852069855, 0.0057166460901498795, -0.052231207489967346, -0.005727093666791916, 0.06085424870252609, -0.06288310140371323, -0.02685791254043579, 0.06571818143129349, -0.0018000482814386487, 0.05255283787846565, 0.07020477950572968, -0.003773275762796402, 0.07504060119390488, -0.07962339371442795, 0.0025439783930778503, -0.0401306226849556, -0.0009651075233705342, -0.06348789483308792, -0.04820660129189491, -0.06873118132352829, 0.03899158164858818, -0.04744284600019455, -0.0345168262720108, -0.03800461068749428, -0.03294319659471512, -0.06600415706634521, -0.06258612126111984, 0.02914377674460411, -0.029370952397584915, -0.019297126680612564, -0.0422549694776535, -0.006668147165328264, 0.010420973412692547, 0.026378491893410683, 0.07836125046014786, -0.006375821772962809, 0.01533565390855074, -0.017063653096556664, -0.05901741608977318, 0.052894964814186096, -0.08578675240278244, 0.05552465841174126, -0.019056221470236778, -7.038655525093418e-08, -0.014460382051765919, 0.0005324578960426152, -0.018114140257239342, 0.0846986249089241, 0.045341070741415024, 0.0045307171531021595, -0.048977188766002655, -0.013440519571304321, -0.00803973339498043, -0.04075126722455025, 0.06111753731966019, -0.06265364587306976, -0.04015813767910004, 0.024126339703798294, 0.017094112932682037, 0.02695605903863907, 0.012655491009354591, 0.05322140082716942, -0.02154620923101902, 0.046513572335243225, 0.0695357695221901, 0.03776576370000839, 0.06322641670703888, -0.03311258554458618, 0.10946618020534515, -0.06918099522590637, -0.011124921031296253, 0.09895365685224533, -0.003091235179454088, -0.04194175824522972, -0.047508470714092255, -0.013720951043069363, -0.0003026306221727282, 0.008910780772566795, 0.02156572788953781, -0.041020069271326065, 0.09895775467157364, -0.04963810369372368, -0.01718038134276867, 0.0031176095362752676, 0.0366571769118309, 0.05249801650643349, -0.05781322717666626, 0.07428218424320221, 0.00935098435729742, -0.02257143333554268, 0.018602261319756508, -0.02634582668542862, 0.01231160294264555, 0.06454499810934067, -0.014527530409395695, -0.07247433811426163, 0.08392378687858582, 0.046579550951719284, -0.0052912174724042416, -0.007301673758774996, -0.014339487068355083, 0.011652093380689621, -0.003095144871622324, 0.0004580764507409185, 0.05018751323223114, -0.02401689440011978, -0.08346157521009445, 0.01763996109366417]}\n",
      "INFO:__main__:\n",
      "\n",
      "INFO:__main__:chunk number 1, chunk len 643: {'content': ' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n', 'chunk_id': 1, 'token_count': 113, 'start_token': 462, 'end_token': 575, 'source': 'basic_info.md', 'embedding': [0.0363936573266983, -0.04721515253186226, -0.007821554318070412, 0.07464204728603363, 0.038892559707164764, -0.008870790712535381, 0.06886232644319534, 0.03157149255275726, -0.04077831283211708, -0.04098472371697426, -0.05685608834028244, 0.020541483536362648, 0.03733716905117035, 0.0007328131468966603, 0.04675740748643875, 0.09583447873592377, 0.0761110931634903, -0.13633762300014496, -0.033627044409513474, -0.1121724396944046, -0.04438856244087219, -0.037729162722826004, -0.010460120625793934, 0.008323900401592255, -0.02860393188893795, 0.01593931019306183, 0.053396303206682205, 0.019571110606193542, -0.025811435654759407, 0.009350876323878765, 0.01291793491691351, 0.06360358744859695, 0.07104562222957611, 0.05033747851848602, -0.06486839056015015, -0.008941625244915485, 0.010788412764668465, 0.009743942879140377, -0.05741459131240845, -0.00608662748709321, -0.07777732610702515, -0.07418234646320343, 0.02136138826608658, 0.02302069589495659, 0.025865137577056885, -0.07717783749103546, 0.023798365145921707, 0.010137784294784069, -0.07234031707048416, 0.05292895436286926, -0.11813370883464813, -0.07219158113002777, -0.013122293166816235, 0.08105333894491196, 0.011272777803242207, 0.04254589229822159, -0.002672934904694557, 0.011358343996107578, 0.04671330749988556, -0.048492033034563065, -0.05324813723564148, -0.015070577152073383, -0.06369835138320923, -0.001140260836109519, -0.005241424310952425, 0.04864399880170822, -0.047840531915426254, 0.07917987555265427, -0.0012271851301193237, -0.015223417431116104, -0.01474134624004364, -0.038503266870975494, -0.05294923484325409, -0.013987241312861443, 0.002068133093416691, 0.029884055256843567, 0.01695658080279827, 0.005543946288526058, 0.03779858723282814, -0.008352300152182579, -0.01048574410378933, 0.006978543475270271, -0.08731814473867416, 0.042988523840904236, 0.027371618896722794, -0.06831620633602142, 0.010529765859246254, 0.03243650496006012, -0.04873130843043327, 0.014121555723249912, -0.07257675379514694, 0.023237435147166252, 0.026124902069568634, -0.029247919097542763, -0.055340029299259186, 0.04920800402760506, -0.030637726187705994, -0.10788228362798691, -0.0036569153890013695, 0.034899696707725525, -0.023215625435113907, 0.04227299243211746, 0.028042826801538467, -0.031185122206807137, -0.06915341317653656, -0.05381932109594345, 0.019306184723973274, 0.0908350944519043, 0.018729742616415024, 0.011006435379385948, -0.07803981751203537, 0.020497146993875504, -0.012092215940356255, -0.08609704673290253, 0.03690066933631897, 0.005373470485210419, -0.029008829966187477, 0.0002968886692542583, -0.01862221211194992, 0.0926661342382431, -0.03139226511120796, 0.027971375733613968, 0.10947129875421524, -0.002309262752532959, -0.01420572679489851, 0.03167308121919632, -0.026634085923433304, 4.741002713710496e-33, -0.037147291004657745, 0.023366862908005714, 0.008597384206950665, 0.0648154467344284, 0.0711667612195015, -0.0368284173309803, 0.04880756139755249, 0.030846448615193367, 0.019239168614149094, -0.03981902822852135, -0.05149843916296959, 0.14247038960456848, 0.0029701769817620516, 0.050627756863832474, 0.060469742864370346, -0.07017119973897934, -0.09420798718929291, 0.10874830931425095, -0.040683768689632416, -0.0027793259359896183, -0.003715791506692767, -0.08545726537704468, -0.018911391496658325, 0.011971509084105492, 0.11961878836154938, -0.00983697921037674, 0.08657155185937881, 0.057797763496637344, 0.07976078987121582, 0.0027297374326735735, 0.03750459477305412, 0.009558292105793953, 0.017341913655400276, -0.06624554842710495, -0.032644957304000854, 0.026883475482463837, -0.05296939238905907, -0.06769482791423798, 0.06673765182495117, 0.013177242130041122, -0.02535451203584671, 0.025013960897922516, -0.0519951656460762, -0.022476384416222572, -0.0982326790690422, 0.0967942476272583, 0.009313630871474743, -0.032506346702575684, -0.06308194994926453, -0.007672548294067383, 0.018824394792318344, 0.003340423107147217, 0.03156216815114021, 0.12239278852939606, 0.0006233641761355102, -0.019359642639756203, 0.012480110861361027, -0.05393340438604355, 0.06631534546613693, 0.011655401438474655, -0.024118853732943535, -0.0050012883730232716, 0.0020663507748395205, -0.037266455590724945, 0.018895311281085014, 0.05493047460913658, 0.05169136822223663, 0.07915733754634857, 0.020500915125012398, -0.045511405915021896, -0.03525737673044205, 0.0026150469202548265, 0.05457685887813568, -0.06514602154493332, 0.029006654396653175, -0.034217532724142075, -0.049453288316726685, -0.022013574838638306, -0.042162731289863586, 0.0012492581736296415, -0.015669601038098335, 0.012104956433176994, 0.04910013824701309, -0.02967236004769802, 0.010393639095127583, -0.004069468006491661, -0.015202297829091549, -0.030246401205658913, -0.14989741146564484, 0.07642921805381775, -0.045825205743312836, 0.08210035413503647, -0.013889296911656857, 0.11796972900629044, 0.03339730203151703, -3.551394716496664e-33, -0.06540866941213608, -0.017933115363121033, -0.0595146119594574, 0.05962417647242546, 0.11169163137674332, -0.0556001253426075, -0.06286873668432236, -0.08030451834201813, 0.06141302362084389, 0.07447844743728638, -0.023267872631549835, -0.07885206490755081, -0.0012568933889269829, -0.007520816754549742, -0.0032597086392343044, -0.07849391549825668, 0.038829393684864044, -0.0810445100069046, -0.002409113571047783, -0.0038306075148284435, -0.02506333403289318, 0.0448908694088459, -0.11357342451810837, -0.09317542612552643, -0.055334970355033875, 0.09584920108318329, -0.002221443457528949, 0.029591094702482224, 0.01790752448141575, -0.011260777711868286, -0.02390034683048725, 0.005605227779597044, -0.021528011187911034, -0.07092804461717606, -0.00015163850912358612, 0.031246358528733253, -0.04433194175362587, -0.0066037243232131, -0.017601901665329933, 0.08582387119531631, 0.0895177349448204, -0.019263414666056633, -0.06762862950563431, -0.008407642133533955, -0.026093970984220505, 0.05363650247454643, -0.009431117214262486, -0.06297705322504044, -0.05172489583492279, -0.07578040659427643, 0.0030648435931652784, -0.0035193744115531445, -0.06369706243276596, -0.0022287494502961636, 0.00899548176676035, 0.024840595200657845, 0.09528696537017822, -0.02721717208623886, 0.0472102053463459, -0.0004799629095941782, -0.01986495405435562, -0.03333710506558418, 0.11350921541452408, -0.035317327827215195, -0.002112415386363864, -0.004717591684311628, 0.11286924034357071, -0.03421592339873314, -0.007727072574198246, 0.021484699100255966, 0.008715881034731865, 0.0017732487758621573, -0.009400182403624058, 0.11519360542297363, 0.009769880212843418, 0.004755990579724312, -0.033325791358947754, -0.02036478742957115, -0.040609877556562424, -0.01625976152718067, -0.0726277157664299, 0.06536005437374115, 0.01809682510793209, -0.014581054449081421, 0.005842441692948341, 0.005080013070255518, 0.009220115840435028, -0.021922525018453598, -0.040535639971494675, -0.02844998612999916, -0.06677167117595673, -0.01951848715543747, -0.07909655570983887, 0.03255394473671913, -0.0035922464448958635, -5.2593460253547164e-08, -0.10016784816980362, 0.0064066331833601, 0.044261958450078964, 0.03999369218945503, -0.0040851496160030365, -0.04018077626824379, -0.011750987730920315, 0.09670307487249374, 0.063524529337883, -0.020552892237901688, 0.13588574528694153, -0.05987399071455002, -0.017108814790844917, 0.09200557321310043, 0.0808098241686821, -0.03941766545176506, 0.052079591900110245, -0.011547591537237167, -0.04458332806825638, -0.04482792690396309, 0.04564361274242401, 0.07284733653068542, 0.037326086312532425, 0.009754978120326996, 0.10079850256443024, 0.029297417029738426, 0.016366831958293915, 0.11313001811504364, 0.037685077637434006, -0.0039403182454407215, -0.01569466106593609, 0.017564941197633743, -0.005119386129081249, -0.021363889798521996, -0.01961342990398407, -0.025455359369516373, -0.004331248812377453, -0.013333402574062347, -0.010288344696164131, 0.07589704543352127, -0.011387314647436142, 0.06820791959762573, -0.08785838633775711, 0.02185390703380108, 0.020857451483607292, 0.03631506860256195, -0.052316706627607346, -0.045959144830703735, -0.05158960446715355, 0.03284243121743202, -0.027926115319132805, -0.04110018163919449, 0.028645789250731468, 0.0618039108812809, 0.06144455447793007, -0.02964125946164131, -0.0288839228451252, -0.0182818491011858, 0.05122284218668938, 0.002592997392639518, -0.037950776517391205, -0.03739002346992493, -0.132870152592659, 0.10080353915691376]}\n",
      "INFO:__main__:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind, chunk in enumerate(chunks):\n",
    "    logger.info(f\"chunk number {ind}, chunk len {len(chunk['content'])}: {chunk}\")\n",
    "    logger.info(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0e1005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 3 embeddings\n",
      "INFO:__main__:Embedded batch 1/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #  Generate embeddings in batches (HuggingFaceClient)\n",
    "# texts = [chunk[\"content\"] for chunk in chunks]\n",
    "# embeddings = []\n",
    "\n",
    "# for i in range(0, len(texts), batch_size):\n",
    "#     batch = texts[i:i + batch_size]\n",
    "#     batch_embeddings = hf_client.get_embeddings(batch)\n",
    "#     embeddings.extend(batch_embeddings)   # adds each embedding vector\n",
    "#     logger.info(f\"Embedded batch {i // batch_size + 1}/{(len(texts) + batch_size - 1) // batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9530b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert into database (PgVectorDB)\n",
    "# db_client.insert_chunks(chunks) # embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f497e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Log statistics (TextProcessor)\n",
    "# stats = text_processor.get_chunk_stats(chunks)\n",
    "# logger.info(\n",
    "#     f\"Loaded {stats['total_chunks']} chunks, \"\n",
    "#     f\"avg {stats['avg_tokens']:.0f} tokens/chunk\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d616b",
   "metadata": {},
   "source": [
    "## Query the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query_rag(question, text_processor, hf_client, db_client, k=5):\n",
    "#     \"\"\"\n",
    "#     Execute RAG query: embed → search → assemble context → generate answer.\n",
    "    \n",
    "#     Args:\n",
    "#         question: User query\n",
    "#         text_processor: TextProcessor instance\n",
    "#         hf_client: HuggingFaceClient instance\n",
    "#         db_client: PgVectorDB instance\n",
    "#         k: Number of chunks to retrieve\n",
    "        \n",
    "#     Returns:\n",
    "#         dict: {\"answer\": str, \"sources\": list, \"num_chunks\": int}\n",
    "#     \"\"\"\n",
    "\n",
    "#     # 1. Embed question\n",
    "#     query_embedding = hf_client.get_embeddings([question])[0]\n",
    "#     if not isinstance(query_embedding, list):\n",
    "#         query_embedding = query_embedding.tolist()\n",
    "    \n",
    "#     # 2. Search database with LOWER threshold\n",
    "#     chunks = db_client.search(\n",
    "#         query_embedding, \n",
    "#         k=k, \n",
    "#         similarity_threshold=0.3  # ← CHANGE: 0.7 → 0.3\n",
    "#     )\n",
    "    \n",
    "#     if not chunks:\n",
    "#         return {\n",
    "#             \"answer\": \"No relevant information found.\",\n",
    "#             \"sources\": [],\n",
    "#             \"num_chunks\": 0\n",
    "#         }\n",
    "    \n",
    "#     # 3. Assemble context\n",
    "#     context = text_processor.assemble_context(chunks, question=question)\n",
    "    \n",
    "#     # 4. Generate answer\n",
    "#     try:\n",
    "#         answer = hf_client.generate_answer(question, context)\n",
    "#         if not answer or len(answer) < 10:\n",
    "#             answer = text_processor.create_fallback(chunks)\n",
    "#     except:\n",
    "#         answer = text_processor.create_fallback(chunks)\n",
    "    \n",
    "#     return {\n",
    "#         \"answer\": answer,\n",
    "#         \"sources\": chunks,\n",
    "#         \"num_chunks\": len(chunks)\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4dd353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# result = query_rag(\n",
    "#     question=\"what is refund policy?\",\n",
    "#     text_processor=text_processor,\n",
    "#     hf_client=hf_client,\n",
    "#     db_client=db_client,\n",
    "#     k=5\n",
    "# )\n",
    "\n",
    "# print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418c1f9",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2f41af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n",
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07321703433990479, 0.10643117874860764, 0.07387036830186844, 0.078147754073143, 0.046925924718379974, 0.0721328854560852, 0.013906000182032585, -0.02369273081421852, -0.0615106038749218, -0.06274979561567307, -0.018684348091483116, 0.025482309982180595, 0.012852526269853115, -0.04796987399458885, -0.04774804040789604, -0.01256596390157938, -0.011400102637708187, -0.04338683560490608, -0.05103318765759468, -0.01570521667599678, -0.06017197296023369, 0.08440078794956207, 0.08455660939216614, -0.03912951424717903, -0.06467852741479874, 0.045355647802352905, 0.018806571140885353, -0.045225538313388824, -0.07094831764698029, -0.04065645858645439, 0.033490847796201706, 0.021872708573937416, 0.025714468210935593, 0.021797820925712585, 0.09821108728647232, 0.07279461622238159, -0.07994870096445084, 0.059448935091495514, -0.01713724248111248, 0.0026676850393414497, -0.016397647559642792, -0.05995016172528267, -0.03052023984491825, 0.051142700016498566, 0.017188958823680878, 0.01412486657500267, -0.012567107565701008, 0.07653184235095978, 0.027124416083097458, -0.0011088084429502487, 0.03726604953408241, -0.10070927441120148, -0.030164621770381927, -0.05014963075518608, 0.03115587867796421, -0.05464931204915047, -0.032748907804489136, -0.04474679380655289, -0.10266287624835968, 0.007772236596792936, -0.025316854938864708, 0.017832836136221886, -0.06205974891781807, -0.0021896716207265854, 0.03056340664625168, 0.04723276197910309, -0.014545259065926075, 0.04866226390004158, -0.02320653572678566, -0.04183916747570038, 0.03920944780111313, 0.02404538355767727, -0.06396611779928207, 0.04132384434342384, -0.04347393289208412, -0.011816595681011677, -0.011210382916033268, -0.049317046999931335, 0.10630473494529724, 0.004837505519390106, -0.06877201795578003, -0.10487893968820572, 0.012030504643917084, 0.0374428816139698, 0.049441780894994736, 0.043624915182590485, 0.018975382670760155, -0.06902483105659485, -0.058211393654346466, -0.022732941433787346, 0.06515280902385712, -0.13618381321430206, 0.06679204851388931, 0.025230495259165764, -0.1292230784893036, -0.032438069581985474, -0.025171220302581787, -0.005410287994891405, -0.017186567187309265, 0.1413402110338211, 0.021686479449272156, -0.028422990813851357, 0.0317353829741478, 0.0310823917388916, -0.028170431032776833, -0.0737515389919281, 0.03694925457239151, -0.06864883750677109, -0.031689926981925964, -0.014091111719608307, 0.03654959797859192, 0.010896295309066772, -0.06703317165374756, -0.04192610830068588, -0.01724766381084919, -0.10937660932540894, 0.03791801258921623, 0.06816761195659637, 0.1541554182767868, -0.025548020377755165, 0.014825355261564255, 0.004666272550821304, -0.08550263196229935, -0.04218405485153198, -0.1121813952922821, -0.11470161378383636, -0.027155747637152672, -3.0964986065375933e-33, -0.024271102622151375, 0.07919815182685852, -0.02362385205924511, 0.07390093803405762, 0.08087051659822464, -0.02616812288761139, 0.05350286886096001, -0.005501504056155682, -0.03183478116989136, 0.0730062872171402, 0.014722841791808605, -0.00020380981732159853, 0.0902722179889679, 0.022965382784605026, -0.08713822811841965, 0.05018927529454231, -0.05991758406162262, 0.02474871836602688, -0.0689375177025795, -0.0015721258241683245, 0.02247300185263157, 0.013273538090288639, 0.032955192029476166, 0.00743471784517169, -0.043062932789325714, -0.0009990062098950148, -0.0077520254999399185, -0.0955892875790596, -0.020001495257019997, 0.023335279896855354, 0.015701420605182648, 0.027487749233841896, 0.04727174714207649, 0.012958582490682602, 0.01764601096510887, 0.02341359294950962, -0.05217917263507843, -0.047933921217918396, 0.048662103712558746, 0.024841930717229843, -0.05331824719905853, 0.026740318164229393, -0.00517841475084424, -0.05356606841087341, 0.09946516901254654, 0.06572862714529037, 0.11725663393735886, 0.03731350973248482, 0.09356106072664261, 0.002034576376900077, 0.012591727077960968, -0.04676780104637146, -0.10381577908992767, -0.02412901632487774, -0.036652177572250366, -0.05981767550110817, 0.06019110232591629, 0.010012729093432426, 0.042091988027095795, 0.010623282752931118, 0.0730864554643631, 0.07153832167387009, 0.046669136732816696, 0.08111046254634857, 0.004547366872429848, -0.09471700340509415, -0.006875857710838318, -0.1486010104417801, 0.025088734924793243, -0.05656248703598976, -0.018368180841207504, 0.008303879760205746, -0.007074556779116392, 0.0616222620010376, -0.03627900406718254, -0.004677227698266506, 0.06632983684539795, 0.024657929316163063, 0.03597676008939743, -0.010820659808814526, -0.024411985650658607, -0.03365962952375412, -0.04465344548225403, -0.07677821815013885, 0.020129162818193436, 0.02178276889026165, 0.03479945659637451, -0.0430513471364975, -0.06104777380824089, -0.030116349458694458, -0.06242554262280464, 0.009708057157695293, -0.03152932971715927, -0.004709975328296423, 0.03551482409238815, 1.4292023067507196e-33, 0.05856236815452576, -0.04716302827000618, 0.09010261297225952, -0.012456245720386505, 0.023684866726398468, 0.016226712614297867, 0.042779285460710526, 0.02033381722867489, 0.0324159637093544, 0.09160412102937698, -0.05598634481430054, 0.04475492984056473, 0.07404828071594238, -0.018996911123394966, -0.08476124703884125, 0.0039005507715046406, 0.05897708609700203, -0.039245039224624634, -0.05804603174328804, 0.0053214761428534985, -0.11410156637430191, 0.031022142618894577, -0.028204835951328278, 0.05264011025428772, 0.0403280034661293, 0.0012429330963641405, 0.09654460847377777, -0.015677575021982193, 0.036697980016469955, -0.03606896474957466, -0.018066367134451866, -0.03208184987306595, -0.05385717377066612, 0.13188423216342926, -0.08271127939224243, 0.014883978292346, 0.07026667147874832, -0.0016358488937839866, 0.013210195116698742, 0.13151241838932037, 0.06908698379993439, -0.008206391707062721, 0.0010566278360784054, 0.059694111347198486, -0.029611559584736824, -0.05620262399315834, -0.04490720480680466, -0.07282696664333344, 0.04400969296693802, 0.03186527267098427, -0.05207359045743942, -0.001951668062247336, 0.05684669315814972, -0.0032958597876131535, -0.022864090278744698, 0.07014196366071701, -0.09668996930122375, -0.03749575465917587, 0.004290886223316193, 0.021116288378834724, 0.03476167097687721, 0.032362766563892365, 0.07772946357727051, -0.05083678662776947, -0.027227995917201042, -0.030842488631606102, -0.020692480728030205, -0.028386646881699562, -0.011454019695520401, -0.018092257902026176, -0.03523392975330353, -0.025066500529646873, -0.03162900730967522, -0.03871072456240654, -0.017010526731610298, 0.03621300682425499, 0.04240000620484352, -0.03439633548259735, -0.04000873491168022, 0.022549057379364967, -0.023888515308499336, -0.01812911406159401, -0.11196406930685043, 0.0615159310400486, 0.07883121073246002, 0.01743815839290619, 0.0348367877304554, -0.05064745247364044, 0.02189643494784832, -0.0012607527896761894, 0.03510793298482895, 0.026341162621974945, 0.06443646550178528, -0.004930404946208, -0.08699025213718414, -1.2604403742955128e-08, 0.026680387556552887, 0.013729853555560112, 0.05067678168416023, -0.039208196103572845, 0.012189390137791634, -0.03892364725470543, 0.007943229749798775, -0.07419905066490173, -0.007830954156816006, 0.040574755519628525, 0.014663871377706528, 0.0045051611959934235, -0.027539782226085663, 0.00035499566001817584, 0.03432674705982208, -0.04161263629794121, -0.03916378319263458, 0.025239210575819016, -0.06428077816963196, 0.027055198326706886, -0.0016586470883339643, 0.05436961352825165, -0.016274312511086464, -0.05105457454919815, 0.011123391799628735, 0.05238139629364014, -0.019861681386828423, 0.009630671702325344, -0.027699995785951614, 0.03785236179828644, 0.008601686917245388, 0.04096372798085213, 0.05752088129520416, -0.08790893107652664, -0.0132102370262146, -0.0023777750320732594, 0.10101774334907532, -0.018680615350604057, 0.010824999772012234, 0.04373256117105484, -0.003048273967579007, 0.02394903264939785, 0.003187344642356038, 0.06134592369198799, 0.0239458829164505, 0.021494971588253975, 0.0033978221472352743, -0.05900397524237633, -0.03819501772522926, -0.005800149403512478, 0.06023765727877617, -0.02590269409120083, 0.07819796353578568, 0.07280883938074112, -0.03391168266534805, 0.0763622373342514, 0.05055329203605652, 0.013284968212246895, 0.023601198568940163, 0.021367961540818214, -0.019668802618980408, -0.053133245557546616, 0.012714119628071785, 0.07432839274406433]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.07321703433990479,\n",
       " 0.10643117874860764,\n",
       " 0.07387036830186844,\n",
       " 0.078147754073143,\n",
       " 0.046925924718379974,\n",
       " 0.0721328854560852,\n",
       " 0.013906000182032585,\n",
       " -0.02369273081421852,\n",
       " -0.0615106038749218,\n",
       " -0.06274979561567307,\n",
       " -0.018684348091483116,\n",
       " 0.025482309982180595,\n",
       " 0.012852526269853115,\n",
       " -0.04796987399458885,\n",
       " -0.04774804040789604,\n",
       " -0.01256596390157938,\n",
       " -0.011400102637708187,\n",
       " -0.04338683560490608,\n",
       " -0.05103318765759468,\n",
       " -0.01570521667599678,\n",
       " -0.06017197296023369,\n",
       " 0.08440078794956207,\n",
       " 0.08455660939216614,\n",
       " -0.03912951424717903,\n",
       " -0.06467852741479874,\n",
       " 0.045355647802352905,\n",
       " 0.018806571140885353,\n",
       " -0.045225538313388824,\n",
       " -0.07094831764698029,\n",
       " -0.04065645858645439,\n",
       " 0.033490847796201706,\n",
       " 0.021872708573937416,\n",
       " 0.025714468210935593,\n",
       " 0.021797820925712585,\n",
       " 0.09821108728647232,\n",
       " 0.07279461622238159,\n",
       " -0.07994870096445084,\n",
       " 0.059448935091495514,\n",
       " -0.01713724248111248,\n",
       " 0.0026676850393414497,\n",
       " -0.016397647559642792,\n",
       " -0.05995016172528267,\n",
       " -0.03052023984491825,\n",
       " 0.051142700016498566,\n",
       " 0.017188958823680878,\n",
       " 0.01412486657500267,\n",
       " -0.012567107565701008,\n",
       " 0.07653184235095978,\n",
       " 0.027124416083097458,\n",
       " -0.0011088084429502487,\n",
       " 0.03726604953408241,\n",
       " -0.10070927441120148,\n",
       " -0.030164621770381927,\n",
       " -0.05014963075518608,\n",
       " 0.03115587867796421,\n",
       " -0.05464931204915047,\n",
       " -0.032748907804489136,\n",
       " -0.04474679380655289,\n",
       " -0.10266287624835968,\n",
       " 0.007772236596792936,\n",
       " -0.025316854938864708,\n",
       " 0.017832836136221886,\n",
       " -0.06205974891781807,\n",
       " -0.0021896716207265854,\n",
       " 0.03056340664625168,\n",
       " 0.04723276197910309,\n",
       " -0.014545259065926075,\n",
       " 0.04866226390004158,\n",
       " -0.02320653572678566,\n",
       " -0.04183916747570038,\n",
       " 0.03920944780111313,\n",
       " 0.02404538355767727,\n",
       " -0.06396611779928207,\n",
       " 0.04132384434342384,\n",
       " -0.04347393289208412,\n",
       " -0.011816595681011677,\n",
       " -0.011210382916033268,\n",
       " -0.049317046999931335,\n",
       " 0.10630473494529724,\n",
       " 0.004837505519390106,\n",
       " -0.06877201795578003,\n",
       " -0.10487893968820572,\n",
       " 0.012030504643917084,\n",
       " 0.0374428816139698,\n",
       " 0.049441780894994736,\n",
       " 0.043624915182590485,\n",
       " 0.018975382670760155,\n",
       " -0.06902483105659485,\n",
       " -0.058211393654346466,\n",
       " -0.022732941433787346,\n",
       " 0.06515280902385712,\n",
       " -0.13618381321430206,\n",
       " 0.06679204851388931,\n",
       " 0.025230495259165764,\n",
       " -0.1292230784893036,\n",
       " -0.032438069581985474,\n",
       " -0.025171220302581787,\n",
       " -0.005410287994891405,\n",
       " -0.017186567187309265,\n",
       " 0.1413402110338211,\n",
       " 0.021686479449272156,\n",
       " -0.028422990813851357,\n",
       " 0.0317353829741478,\n",
       " 0.0310823917388916,\n",
       " -0.028170431032776833,\n",
       " -0.0737515389919281,\n",
       " 0.03694925457239151,\n",
       " -0.06864883750677109,\n",
       " -0.031689926981925964,\n",
       " -0.014091111719608307,\n",
       " 0.03654959797859192,\n",
       " 0.010896295309066772,\n",
       " -0.06703317165374756,\n",
       " -0.04192610830068588,\n",
       " -0.01724766381084919,\n",
       " -0.10937660932540894,\n",
       " 0.03791801258921623,\n",
       " 0.06816761195659637,\n",
       " 0.1541554182767868,\n",
       " -0.025548020377755165,\n",
       " 0.014825355261564255,\n",
       " 0.004666272550821304,\n",
       " -0.08550263196229935,\n",
       " -0.04218405485153198,\n",
       " -0.1121813952922821,\n",
       " -0.11470161378383636,\n",
       " -0.027155747637152672,\n",
       " -3.0964986065375933e-33,\n",
       " -0.024271102622151375,\n",
       " 0.07919815182685852,\n",
       " -0.02362385205924511,\n",
       " 0.07390093803405762,\n",
       " 0.08087051659822464,\n",
       " -0.02616812288761139,\n",
       " 0.05350286886096001,\n",
       " -0.005501504056155682,\n",
       " -0.03183478116989136,\n",
       " 0.0730062872171402,\n",
       " 0.014722841791808605,\n",
       " -0.00020380981732159853,\n",
       " 0.0902722179889679,\n",
       " 0.022965382784605026,\n",
       " -0.08713822811841965,\n",
       " 0.05018927529454231,\n",
       " -0.05991758406162262,\n",
       " 0.02474871836602688,\n",
       " -0.0689375177025795,\n",
       " -0.0015721258241683245,\n",
       " 0.02247300185263157,\n",
       " 0.013273538090288639,\n",
       " 0.032955192029476166,\n",
       " 0.00743471784517169,\n",
       " -0.043062932789325714,\n",
       " -0.0009990062098950148,\n",
       " -0.0077520254999399185,\n",
       " -0.0955892875790596,\n",
       " -0.020001495257019997,\n",
       " 0.023335279896855354,\n",
       " 0.015701420605182648,\n",
       " 0.027487749233841896,\n",
       " 0.04727174714207649,\n",
       " 0.012958582490682602,\n",
       " 0.01764601096510887,\n",
       " 0.02341359294950962,\n",
       " -0.05217917263507843,\n",
       " -0.047933921217918396,\n",
       " 0.048662103712558746,\n",
       " 0.024841930717229843,\n",
       " -0.05331824719905853,\n",
       " 0.026740318164229393,\n",
       " -0.00517841475084424,\n",
       " -0.05356606841087341,\n",
       " 0.09946516901254654,\n",
       " 0.06572862714529037,\n",
       " 0.11725663393735886,\n",
       " 0.03731350973248482,\n",
       " 0.09356106072664261,\n",
       " 0.002034576376900077,\n",
       " 0.012591727077960968,\n",
       " -0.04676780104637146,\n",
       " -0.10381577908992767,\n",
       " -0.02412901632487774,\n",
       " -0.036652177572250366,\n",
       " -0.05981767550110817,\n",
       " 0.06019110232591629,\n",
       " 0.010012729093432426,\n",
       " 0.042091988027095795,\n",
       " 0.010623282752931118,\n",
       " 0.0730864554643631,\n",
       " 0.07153832167387009,\n",
       " 0.046669136732816696,\n",
       " 0.08111046254634857,\n",
       " 0.004547366872429848,\n",
       " -0.09471700340509415,\n",
       " -0.006875857710838318,\n",
       " -0.1486010104417801,\n",
       " 0.025088734924793243,\n",
       " -0.05656248703598976,\n",
       " -0.018368180841207504,\n",
       " 0.008303879760205746,\n",
       " -0.007074556779116392,\n",
       " 0.0616222620010376,\n",
       " -0.03627900406718254,\n",
       " -0.004677227698266506,\n",
       " 0.06632983684539795,\n",
       " 0.024657929316163063,\n",
       " 0.03597676008939743,\n",
       " -0.010820659808814526,\n",
       " -0.024411985650658607,\n",
       " -0.03365962952375412,\n",
       " -0.04465344548225403,\n",
       " -0.07677821815013885,\n",
       " 0.020129162818193436,\n",
       " 0.02178276889026165,\n",
       " 0.03479945659637451,\n",
       " -0.0430513471364975,\n",
       " -0.06104777380824089,\n",
       " -0.030116349458694458,\n",
       " -0.06242554262280464,\n",
       " 0.009708057157695293,\n",
       " -0.03152932971715927,\n",
       " -0.004709975328296423,\n",
       " 0.03551482409238815,\n",
       " 1.4292023067507196e-33,\n",
       " 0.05856236815452576,\n",
       " -0.04716302827000618,\n",
       " 0.09010261297225952,\n",
       " -0.012456245720386505,\n",
       " 0.023684866726398468,\n",
       " 0.016226712614297867,\n",
       " 0.042779285460710526,\n",
       " 0.02033381722867489,\n",
       " 0.0324159637093544,\n",
       " 0.09160412102937698,\n",
       " -0.05598634481430054,\n",
       " 0.04475492984056473,\n",
       " 0.07404828071594238,\n",
       " -0.018996911123394966,\n",
       " -0.08476124703884125,\n",
       " 0.0039005507715046406,\n",
       " 0.05897708609700203,\n",
       " -0.039245039224624634,\n",
       " -0.05804603174328804,\n",
       " 0.0053214761428534985,\n",
       " -0.11410156637430191,\n",
       " 0.031022142618894577,\n",
       " -0.028204835951328278,\n",
       " 0.05264011025428772,\n",
       " 0.0403280034661293,\n",
       " 0.0012429330963641405,\n",
       " 0.09654460847377777,\n",
       " -0.015677575021982193,\n",
       " 0.036697980016469955,\n",
       " -0.03606896474957466,\n",
       " -0.018066367134451866,\n",
       " -0.03208184987306595,\n",
       " -0.05385717377066612,\n",
       " 0.13188423216342926,\n",
       " -0.08271127939224243,\n",
       " 0.014883978292346,\n",
       " 0.07026667147874832,\n",
       " -0.0016358488937839866,\n",
       " 0.013210195116698742,\n",
       " 0.13151241838932037,\n",
       " 0.06908698379993439,\n",
       " -0.008206391707062721,\n",
       " 0.0010566278360784054,\n",
       " 0.059694111347198486,\n",
       " -0.029611559584736824,\n",
       " -0.05620262399315834,\n",
       " -0.04490720480680466,\n",
       " -0.07282696664333344,\n",
       " 0.04400969296693802,\n",
       " 0.03186527267098427,\n",
       " -0.05207359045743942,\n",
       " -0.001951668062247336,\n",
       " 0.05684669315814972,\n",
       " -0.0032958597876131535,\n",
       " -0.022864090278744698,\n",
       " 0.07014196366071701,\n",
       " -0.09668996930122375,\n",
       " -0.03749575465917587,\n",
       " 0.004290886223316193,\n",
       " 0.021116288378834724,\n",
       " 0.03476167097687721,\n",
       " 0.032362766563892365,\n",
       " 0.07772946357727051,\n",
       " -0.05083678662776947,\n",
       " -0.027227995917201042,\n",
       " -0.030842488631606102,\n",
       " -0.020692480728030205,\n",
       " -0.028386646881699562,\n",
       " -0.011454019695520401,\n",
       " -0.018092257902026176,\n",
       " -0.03523392975330353,\n",
       " -0.025066500529646873,\n",
       " -0.03162900730967522,\n",
       " -0.03871072456240654,\n",
       " -0.017010526731610298,\n",
       " 0.03621300682425499,\n",
       " 0.04240000620484352,\n",
       " -0.03439633548259735,\n",
       " -0.04000873491168022,\n",
       " 0.022549057379364967,\n",
       " -0.023888515308499336,\n",
       " -0.01812911406159401,\n",
       " -0.11196406930685043,\n",
       " 0.0615159310400486,\n",
       " 0.07883121073246002,\n",
       " 0.01743815839290619,\n",
       " 0.0348367877304554,\n",
       " -0.05064745247364044,\n",
       " 0.02189643494784832,\n",
       " -0.0012607527896761894,\n",
       " 0.03510793298482895,\n",
       " 0.026341162621974945,\n",
       " 0.06443646550178528,\n",
       " -0.004930404946208,\n",
       " -0.08699025213718414,\n",
       " -1.2604403742955128e-08,\n",
       " 0.026680387556552887,\n",
       " 0.013729853555560112,\n",
       " 0.05067678168416023,\n",
       " -0.039208196103572845,\n",
       " 0.012189390137791634,\n",
       " -0.03892364725470543,\n",
       " 0.007943229749798775,\n",
       " -0.07419905066490173,\n",
       " -0.007830954156816006,\n",
       " 0.040574755519628525,\n",
       " 0.014663871377706528,\n",
       " 0.0045051611959934235,\n",
       " -0.027539782226085663,\n",
       " 0.00035499566001817584,\n",
       " 0.03432674705982208,\n",
       " -0.04161263629794121,\n",
       " -0.03916378319263458,\n",
       " 0.025239210575819016,\n",
       " -0.06428077816963196,\n",
       " 0.027055198326706886,\n",
       " -0.0016586470883339643,\n",
       " 0.05436961352825165,\n",
       " -0.016274312511086464,\n",
       " -0.05105457454919815,\n",
       " 0.011123391799628735,\n",
       " 0.05238139629364014,\n",
       " -0.019861681386828423,\n",
       " 0.009630671702325344,\n",
       " -0.027699995785951614,\n",
       " 0.03785236179828644,\n",
       " 0.008601686917245388,\n",
       " 0.04096372798085213,\n",
       " 0.05752088129520416,\n",
       " -0.08790893107652664,\n",
       " -0.0132102370262146,\n",
       " -0.0023777750320732594,\n",
       " 0.10101774334907532,\n",
       " -0.018680615350604057,\n",
       " 0.010824999772012234,\n",
       " 0.04373256117105484,\n",
       " -0.003048273967579007,\n",
       " 0.02394903264939785,\n",
       " 0.003187344642356038,\n",
       " 0.06134592369198799,\n",
       " 0.0239458829164505,\n",
       " 0.021494971588253975,\n",
       " 0.0033978221472352743,\n",
       " -0.05900397524237633,\n",
       " -0.03819501772522926,\n",
       " -0.005800149403512478,\n",
       " 0.06023765727877617,\n",
       " -0.02590269409120083,\n",
       " 0.07819796353578568,\n",
       " 0.07280883938074112,\n",
       " -0.03391168266534805,\n",
       " 0.0763622373342514,\n",
       " 0.05055329203605652,\n",
       " 0.013284968212246895,\n",
       " 0.023601198568940163,\n",
       " 0.021367961540818214,\n",
       " -0.019668802618980408,\n",
       " -0.053133245557546616,\n",
       " 0.012714119628071785,\n",
       " 0.07432839274406433]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"Cover letter\" #\"refund policy\"\n",
    "\n",
    "print( hf_client.get_embeddings([question]))\n",
    "\n",
    "query_embedding = hf_client.get_embeddings([question])[0]\n",
    "# if not isinstance(query_embedding, list):\n",
    "#     query_embedding = query_embedding.tolist()\n",
    "query_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aae49f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 2,\n",
       "  'content': '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI',\n",
       "  'source': 'basic_info.md',\n",
       "  'chunk_id': 0,\n",
       "  'start_token': 0,\n",
       "  'end_token': 512,\n",
       "  'token_count': 512,\n",
       "  'similarity': 0.23881937496777672}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = db_client.search_new(query_embedding, k=K, similarity_threshold=SIMILARITY_THRESHOLD)\n",
    "\n",
    "# results = db_client.search(query_embedding, k=5, similarity_threshold=0.2)\n",
    "# print(f\"Found: {len(results)} results\")\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7d29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context: # Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherland\\n\\nQ: what is in Cover letter?\\nA:'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_text = \"\\n\".join([d[\"content\"][:400] for d in chunks])\n",
    "prompt = f\"Context: {context_text[:600]}\\n\\nQ: what is in {question}?\\nA:\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fcccd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # answer = hf_client.generate_answer(question, prompt)\n",
    "\n",
    "# max_new_tokens: int = 512\n",
    "# temperature: float = 0.7\n",
    "\n",
    "# response = hf_client.llm_client.conversational(\n",
    "#     prompt,\n",
    "#     max_new_tokens=max_new_tokens,\n",
    "#     temperature=temperature,\n",
    "#     do_sample=True,\n",
    "#     top_p=0.9,\n",
    "#     return_full_text=False\n",
    "# )\n",
    "\n",
    "# # Extract the generated text from the response\n",
    "# answer = response.generated_text.strip()\n",
    "\n",
    "# answer = response.strip()\n",
    "# logger.info(f\"Generated answer ({len(answer)} chars)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f303c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import InferenceClient\n",
    "\n",
    "# # Replace with your Hugging Face token and prompt\n",
    "# # hf_token = \"your_hf_token_here\"\n",
    "# prompt = \"Context:\"\n",
    "# context_text = \"\\n\".join([d[\"content\"][:400] for d in chunks])\n",
    "\n",
    "\n",
    "# #\"Your context text here\"\n",
    "# question = f\"Q: what is in {question}?\\nA:\" #\"Your question here\"\n",
    "\n",
    "# # Initialize the client with a supported model\n",
    "# llm_client = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.2\", token=HF_TOKEN)\n",
    "\n",
    "# # Format the prompt as a chat-like instruction\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": f\"\"\"<s>[INST] Based on this context:\n",
    "\n",
    "# {context_text[:800]}\n",
    "\n",
    "# Answer: {question} [/INST]\"\"\"\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# # Convert the messages to a single prompt string\n",
    "# prompt = messages[0][\"content\"]\n",
    "\n",
    "# # Generate the answer\n",
    "# response = llm_client.text_generation(\n",
    "#     prompt=prompt,\n",
    "#     max_new_tokens=512,\n",
    "#     temperature=0.7,\n",
    "#     do_sample=True,\n",
    "#     top_p=0.9,\n",
    "#     return_full_text=False\n",
    "# )\n",
    "\n",
    "# # Extract the answer\n",
    "# answer = response.strip()\n",
    "# print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b168d",
   "metadata": {},
   "source": [
    "## Query the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ed694e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client=InferenceClient(\n",
    "                model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                token=HF_TOKEN\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_question=\"what is this cover letter about\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Based on this context:\\n\\n{context_text}\\n\\nAnswer: {llm_question}?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = llm_client.chat_completion(\n",
    "    messages=messages,\n",
    "    max_tokens=500,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31a01894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionOutput(choices=[ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content=\" This cover letter does not provide sufficient information to determine its specific content. It appears to be accompanying a resume or CV and includes some basic contact information and a link to the person's GitHub and LinkedIn profiles. The last two lines suggest that the resume or CV has been generated using a specific tool and saved as a PDF file. However, there is no explicit statement in the cover letter about the purpose of the document or what it is requesting or offering.\", reasoning=None, tool_call_id=None, tool_calls=None), logprobs=None)], created=1767726252925, id='1d9c3a1f-6b9d-476e-b878-40c412e17d3b', model='mistralai/Mistral-7B-Instruct-v0.2', system_fingerprint='', usage=ChatCompletionOutputUsage(completion_tokens=94, prompt_tokens=135, total_tokens=229), object='chat.completion')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39107c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This cover letter does not provide sufficient information to determine the specific topic or purpose of the letter. It includes basic contact information for Mario Theplumber, his email address, phone number, and links to his GitHub and LinkedIn profiles. It also mentions the use of a JSON resume and exporting it as a PDF using the \"caffeine-tweaked\" theme. However, there is no text in the cover letter explaining why Mario is writing the letter or to whom it is being addressed.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d6f1a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "393afbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:text_processor:Context: 512/1348 tokens, 1/1 chunks\n",
      "ERROR:hf_client:Answer generation failed: Model mistralai/Mistral-7B-Instruct-v0.2 is not supported for task text-generation and provider featherless-ai. Supported task: conversational.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to generate answer: Model mistralai/Mistral-7B-Instruct-v0.2 is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/LLM/cv_rag/notebooks/../src/hf_client.py:120\u001b[39m, in \u001b[36mHuggingFaceClient.generate_answer\u001b[39m\u001b[34m(self, question, context, max_new_tokens, temperature)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     answer = response.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/LLM/cv_rag/rag_cv_env/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:2357\u001b[39m, in \u001b[36mInferenceClient.text_generation\u001b[39m\u001b[34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[39m\n\u001b[32m   2356\u001b[39m provider_helper = get_provider_helper(\u001b[38;5;28mself\u001b[39m.provider, task=\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model_id)\n\u001b[32m-> \u001b[39m\u001b[32m2357\u001b[39m request_parameters = \u001b[43mprovider_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2364\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2366\u001b[39m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/LLM/cv_rag/rag_cv_env/lib/python3.13/site-packages/huggingface_hub/inference/_providers/_common.py:93\u001b[39m, in \u001b[36mTaskProviderHelper.prepare_request\u001b[39m\u001b[34m(self, inputs, parameters, headers, model, api_key, extra_payload)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# mapped model from HF model ID\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m provider_mapping_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_mapping_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# default HF headers + user headers (to customize in subclasses)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/LLM/cv_rag/rag_cv_env/lib/python3.13/site-packages/huggingface_hub/inference/_providers/_common.py:171\u001b[39m, in \u001b[36mTaskProviderHelper._prepare_mapping_info\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping.task != \u001b[38;5;28mself\u001b[39m.task:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    172\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not supported for task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and provider \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprovider_mapping.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    174\u001b[39m     )\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m provider_mapping.status == \u001b[33m\"\u001b[39m\u001b[33mstaging\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Model mistralai/Mistral-7B-Instruct-v0.2 is not supported for task text-generation and provider featherless-ai. Supported task: conversational.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m context = text_processor.assemble_context(chunks, question=question)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 4. Generate answer\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# except:\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#     answer = text_processor.create_fallback(chunks)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m answer = \u001b[43mhf_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/LLM/cv_rag/notebooks/../src/hf_client.py:135\u001b[39m, in \u001b[36mHuggingFaceClient.generate_answer\u001b[39m\u001b[34m(self, question, context, max_new_tokens, temperature)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer generation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to generate answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to generate answer: Model mistralai/Mistral-7B-Instruct-v0.2 is not supported for task text-generation and provider featherless-ai. Supported task: conversational."
     ]
    }
   ],
   "source": [
    "# 3. Assemble context\n",
    "context = text_processor.assemble_context(chunks, question=question)\n",
    "\n",
    "# 4. Generate answer\n",
    "# try:\n",
    "    \n",
    "#     if not answer or len(answer) < 10:\n",
    "#         answer = text_processor.create_fallback(chunks)\n",
    "# except:\n",
    "#     answer = text_processor.create_fallback(chunks)\n",
    "answer = hf_client.generate_answer(question, context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fb6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding_str = f\"[{','.join(map(str, query_embedding))}]\"\n",
    "\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            content, source, chunk_id, \n",
    "            start_token, end_token, token_count,\n",
    "            1 - (embedding <=> %s::vector) AS similarity\n",
    "        FROM documents\n",
    "        WHERE 1 - (embedding <=> %s::vector) > %s\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT %s\n",
    "    \"\"\", (query_embedding_str, query_embedding_str, similarity_threshold, query_embedding_str, k))\n",
    "    \n",
    "    results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5ce9d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with distances: [(3,)]\n"
     ]
    }
   ],
   "source": [
    "with db_client.conn.cursor() as cur:\n",
    "    # cur.execute(\"\"\"\n",
    "    #     SELECT \n",
    "    #         content, source, chunk_id, \n",
    "    #         (embedding <=> %s::vector) AS distance\n",
    "    #     FROM documents\n",
    "    #     ORDER BY distance\n",
    "    #     LIMIT %s\n",
    "    # \"\"\", (query_embedding_str, k))\n",
    "    cur.execute(\"SELECT COUNT(*) FROM documents;\")\n",
    "\n",
    "    results = cur.fetchall()\n",
    "    print(\"Results with distances:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616bf904",
   "metadata": {},
   "source": [
    "### query examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d39170f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  '# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI',\n",
       "  'basic_info.md',\n",
       "  0,\n",
       "  0,\n",
       "  512,\n",
       "  512,\n",
       "  0.7611806250322233),\n",
       " (3,\n",
       "  ' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n',\n",
       "  'basic_info.md',\n",
       "  1,\n",
       "  462,\n",
       "  575,\n",
       "  113,\n",
       "  0.9871087018400431),\n",
       " (1,\n",
       "  'Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n',\n",
       "  'policy.txt',\n",
       "  0,\n",
       "  0,\n",
       "  21,\n",
       "  21,\n",
       "  1.0557476596757072)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding_str = f\"[{','.join(map(str, query_embedding))}]\"\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT\n",
    "        id,\n",
    "        content,\n",
    "        source,\n",
    "        chunk_id,\n",
    "        start_token,\n",
    "        end_token,\n",
    "        token_count,\n",
    "        embedding <=> %s::vector AS cosine_distance\n",
    "    FROM documents\n",
    "    ORDER BY cosine_distance\n",
    "\"\"\"\n",
    "\n",
    "# if limit is not None:\n",
    "#     sql += f\" LIMIT {limit}\"\n",
    "\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(sql, (query_embedding_str,))\n",
    "    results = cur.fetchall()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33c1575e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened items.\\n',\n",
       "  'policy.txt',\n",
       "  0,\n",
       "  0,\n",
       "  21,\n",
       "  21,\n",
       "  '[-0.049646314,0.00788142,0.06498598,0.02755123,0.05388102,0.0034853122,0.0019658671,-0.021383384,-0.028284602,0.03796265,0.08782472,0.008704987,-0.0036289226,-0.11326598,-0.03446046,-0.030774001,-0.0074088993,-0.03812605,-0.03755244,-0.010578815,0.04534926,-0.058244433,0.017379388,-0.053542886,0.04122955,0.08540669,-0.056329153,-0.034305654,-0.014205925,-0.01184808,0.044347055,-0.054839652,-0.066744395,-0.054778058,-0.044496957,0.0525469,-0.060063083,-0.09016178,-0.03886948,0.015047273,-0.10945757,0.09787436,-0.0068044807,0.0814983,0.034812823,-0.025477463,0.044552438,-0.044960745,0.07981487,0.024243109,0.0077475174,0.06295065,-0.039939594,0.03283787,0.0010958338,0.062451098,-0.0153706875,0.001572128,-0.028900862,-0.094697304,0.026326738,-0.12996931,-0.032205645,-0.10682113,-0.043133542,-0.06842565,-0.07529022,-0.035768274,-0.046319578,-0.020300878,0.030344663,-0.023127316,-0.012185628,0.018070435,0.03557637,0.068758406,0.03772565,0.035724364,-0.070435636,0.027332285,-0.008490453,0.02905477,0.057123262,-0.07616263,0.02712899,-0.032072637,-0.097215325,0.13218,0.08327734,0.028136384,-0.028457997,-0.008590607,0.00830898,-0.051067267,-0.035594523,-0.04085502,0.022289569,0.02779501,0.015965976,0.002524542,0.047173418,0.020491533,-0.041265544,-0.036367517,0.0083336225,-0.064873755,-0.014163118,0.056326304,-0.09387655,-0.027240222,-0.053923823,-0.031996943,0.08128012,0.053690486,0.023565296,0.004901522,-0.14136508,-0.0395327,0.03678121,-0.0809454,0.038484633,0.116149776,0.12982385,-0.03998795,-0.006852558,0.027987676,0.058342405,7.438405e-34,-0.08264951,0.058669005,-0.05082281,-0.08883916,-0.0049300133,-0.023123477,0.08560432,-0.03292971,0.038037263,0.008588893,-0.028529111,0.06239903,-0.017200839,0.04100152,-0.047722626,0.05193293,0.031940334,0.109185725,0.017698191,-0.07536981,-0.009191761,-0.049382504,0.03981268,-0.018293202,0.045092527,-0.14195044,-0.033014137,0.049315218,0.01256847,-0.020754477,0.09096897,0.0716106,0.040488157,-0.030102627,0.009291273,0.035214324,0.046709232,0.017344385,-0.00815962,0.002590458,0.015482326,-0.024734674,0.020907652,0.0058520916,-0.04825891,-0.08170442,-0.027304329,0.0024504608,-0.01346451,0.0028599813,0.022841694,0.03966998,0.018190267,0.0009540769,-0.060526684,0.019239098,-0.002700773,0.068130665,-0.045085818,-0.01462584,0.06530453,-0.040825848,0.029281767,-0.015639266,-0.12037387,0.024438871,0.01989278,0.0050507803,-0.03210266,0.03266053,0.07642112,0.053972837,0.0050855265,-0.06860122,0.11020092,-0.035307966,-0.0051601557,-0.039572902,0.0031850557,-0.04875035,-0.035990506,-0.075295,-0.035460513,0.05164647,-0.0054809805,0.033279315,0.032784823,-0.07339225,0.050036106,-0.04396997,-0.05539599,-0.061105844,0.018895715,-0.003984471,0.114426926,-1.7986011e-33,0.11194605,-0.014801686,-0.0099682715,0.0060188086,-0.08073471,0.040261958,-0.049790595,0.15681696,-0.00044763187,-0.015900059,-0.04482908,-0.031625684,0.09546129,0.008099757,0.0026743168,0.031960007,0.043684065,-0.068024404,0.075798474,-0.03724952,0.09099106,-0.06865192,0.07700113,0.029445011,-0.07862882,0.018899163,-0.015234211,-0.045513567,0.021616653,-0.008282093,0.04597743,-0.053358883,-0.029382749,0.0036546763,0.08539988,-0.09555421,-0.06980827,0.0016159025,0.037347898,0.048232403,0.047240328,-6.732477e-06,0.032444607,0.0041350615,0.03759868,-0.04772423,-0.036978327,-0.045066595,0.105691575,-0.054877818,-0.018496819,-0.008196493,0.0476224,-0.025268767,-0.040456753,0.04102008,0.07044838,-0.0198397,0.005677869,0.007766888,-0.05067579,-0.06999043,-0.05872271,0.06404345,0.022968207,0.00977119,0.07697866,-0.08530401,0.12958433,-0.060758546,0.006208139,-1.579839e-05,-0.05318334,-0.0057775094,0.04461937,0.11139314,-0.022781745,-0.011761236,0.001114983,0.057904515,0.047071192,0.020149395,0.04345503,0.024592668,0.07045132,-0.10791051,-0.061438654,-0.06478534,0.026868392,0.04963607,0.04559786,-0.050596587,0.08787611,0.04041645,-0.0064321565,-2.532525e-08,0.023269972,0.035706755,0.1103684,0.08296736,0.010415566,0.017311221,0.017326983,0.01451521,-0.013109063,-0.06854716,0.038657032,0.027413711,-0.029383322,-0.0046447013,0.0011398089,-0.062008522,-0.010248148,-0.02808529,0.0593429,0.015660707,-0.010753641,-0.051209576,0.08616439,-0.009529023,-0.04856716,0.039755628,0.04401488,0.041848868,-0.018933404,0.008549238,-0.011188979,0.0052823354,-0.001299196,0.04302374,-0.054155316,-0.0741311,0.07133001,-0.0148736825,0.010997668,-0.004974162,0.03402612,-0.02440553,0.02693963,-0.060796406,-0.01854708,-0.010988053,-0.029017339,-0.048427936,0.05831406,-0.024621736,0.0226889,-0.02731844,-0.031155309,-0.048998225,-0.028604912,-0.017085154,-0.011208461,0.07004192,0.005185721,-0.013591356,-0.02691066,-0.034595635,-0.029331667,-0.017075473]'),\n",
       " ('# Cover letter\\n\\n## Basic info\\n\\n\\nThis is a document with CV summary\\n\\n\\nName: Mario (Marvin) Theplumber\\n\\nemail: mario.thplumber@gmail.com\\nphone: +72787226083\\n\\nNorth Holland, Netherlands\\nhttps://github.com/razmarrus\\nhttps://www.linkedin.com/in/razmarrus/\\n\\nnpm i jsonresume-theme-caffeine-tweaked\\nresume export --theme caffeine-tweaked resume.pdf\\n\\nadress: Beethovenstraat 22-1 1099 LK Rotterdam\\nNetherlands \\n\\nEducation: Brazil State University of Informatics\\n\\n\\n## About me / Role description\\n\\nAs a results-oriented Data Scientist, I believe that combining Machine Learning and Statistics provides businesses with solid answers to their questions. While staying close to the data, I work closely with my business-oriented colleagues to translate business goals into achievable objectives using models.\\n\\nMy focus is on customer and financial analytics, where I assist in improving marketing strategies with a better understanding of customers’ preferences and measuring the effectiveness of promotion with sales prediction. \\n\\nThe outcomes of my work are often presented as regularly updated dashboards and sheets.\\n\\nMy expertise encompasses the full pipeline delivery, from extracting raw data from the warehouse and creating datasets to tuning models and automating updates. Since data investigation and model tuning are iterative processes, I regularly present my findings and progress using clear and concise slides. Knowledgeable in optimizing and updating old models for new requirements, followed by integration into the client’s infrastructure.\\n\\n\\nI do love Data Science because the process of brainstorming new data is quite fun.\\nI see the DS work as an endless process of testing your own ideas. Of course, there are know-how and\\ncommon approaches, but you still must think and improvise to get better results.\\nThat is why data scientist in consulting is a perfect match for me\\n\\nCurrently I live in Amsterdam, while working remotely. I have Netherlands residence permit, so i don’t need to make\\nany additional paperwork to work in Netherlands\\n\\n## Recommendation system\\n \\n I developed a multi-channel recommendation system for a large pharmaceutical client to optimize marketing strategies across 4 communication channels: email, WhatsApp, call-center, and in-person meetings. \\nFour separate ML models were created, each required an individual business approach to define what constituted a successful communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI',\n",
       "  'basic_info.md',\n",
       "  0,\n",
       "  0,\n",
       "  512,\n",
       "  512,\n",
       "  '[-0.10912732,0.043604665,-0.026428064,0.06353767,0.059972785,0.08320456,0.024466723,0.04996594,-0.068952926,-0.08014482,-0.0702288,-0.03195729,0.035834294,-0.025749927,-0.012951597,0.020189995,0.029678358,-0.045693222,-0.06320782,-0.057064097,-0.043311805,0.024978666,0.052971527,-0.015426452,-0.063627146,0.047389153,0.043933135,-0.004281361,-0.07266434,-0.048945185,0.0002380801,0.000522556,0.04057131,0.028018445,0.015068695,0.037887942,-0.037173215,-0.006536062,0.022200868,0.035449617,-0.025223805,-0.102886826,-0.07156573,-0.0273739,0.109197296,-0.061577246,-0.01900104,-0.004012991,-0.011240568,0.06137572,-0.15827954,-0.0067943507,-0.0023941544,-0.024793975,-0.028994571,0.07810951,-0.009715696,-0.030210694,0.027779922,-0.059875045,0.01283881,-0.12923424,-0.035810854,-0.0095829,-0.034077007,-0.0147376275,-0.13259491,0.09894187,-0.10348134,0.0039660647,-0.01066936,0.00039385963,-0.03820254,0.030194758,-0.014312013,0.008484408,-0.0137895,0.016072903,0.009311121,-0.01461322,0.013019096,0.021824976,-0.08861231,0.016337207,-0.019369677,-0.038462896,0.061180893,-0.0038491325,-0.045621894,0.040658485,0.038305335,0.010570395,0.027279213,-0.025562987,-0.030283762,0.04587932,0.037891842,-0.084202215,0.03911833,0.07658816,0.009519585,0.052822318,0.069147944,0.019983688,-0.11218438,-0.029229837,-0.041999932,0.11114934,-0.0071085515,-0.047231924,-0.002540009,0.041522224,-0.16935703,0.0006640588,0.0428559,-0.006832355,-0.07038658,0.0095657455,0.033620946,0.09007457,0.04194602,0.09659568,0.03216747,0.056993883,-0.03189664,0.008141875,-0.057828933,8.998834e-33,-0.053342205,0.06983753,0.028113347,0.089709625,0.053721804,0.0024877656,-0.054978713,0.050600924,-0.006374052,0.0649357,-0.08223593,0.15358278,0.008201278,0.08553855,-0.035253983,0.06453991,-0.0075180703,0.04551109,-0.06466155,-0.024674552,0.09109727,0.019940972,-0.027676955,0.024664063,0.012805782,0.036149267,0.04904086,0.009369082,0.021225745,0.034996267,0.04421315,-0.017003598,0.004318798,-0.039226625,-0.00907813,-0.015974201,-0.08880234,-0.12546001,0.00583532,0.020552937,-0.0930736,0.050182097,0.011618492,0.023766588,-0.10242157,-0.035980944,0.07510561,0.018486975,0.06376918,0.009974388,-0.054602984,-0.10236992,0.049033295,-0.011310538,-0.08204071,0.009820824,0.03182581,-0.02121424,0.002903138,-0.061442316,0.03593901,-0.0076765358,-0.036625963,-0.093796045,-0.04100692,0.011651789,-0.012942385,0.038879845,0.101588264,-0.051649753,0.026339674,0.048356645,0.07941408,0.047670085,0.09204688,-0.014160356,-0.02064247,0.05235711,-0.048725545,-0.019642504,0.06361602,0.013341443,-0.03497473,-0.038972065,0.039812557,0.07151836,0.060642973,-0.047826692,-0.041306708,0.08392601,-0.08406735,0.09498572,-0.008294488,0.07345676,-0.059689365,-9.355167e-33,-0.0020285535,0.00891752,0.04043928,-0.0046558785,0.06771399,0.03433617,-0.07844042,-0.0321396,0.004581158,-0.11368545,-0.030043146,-0.008874339,0.001866636,-0.010235606,-0.031031337,0.07455007,-0.034041137,-0.009026451,-0.095799185,-0.048279442,-0.106996715,0.039699946,-0.04265098,-0.009866947,0.013293576,0.056281686,0.009061678,0.016126439,0.0029305224,0.016765967,-0.06584638,-0.0038996537,-0.10665838,0.005324735,0.011709608,-0.036110777,0.0043854513,-0.08154537,0.015180404,0.07934204,0.060674947,0.026511353,-0.033636156,-0.028211607,0.0021748848,0.0068375687,0.029886533,-0.028820725,0.04749221,-0.032880045,-0.006518829,0.029001253,-0.04421354,0.005716646,-0.052231207,-0.0057270937,0.06085425,-0.0628831,-0.026857913,0.06571818,-0.0018000483,0.052552838,0.07020478,-0.0037732758,0.0750406,-0.07962339,0.0025439784,-0.040130623,-0.0009651075,-0.063487895,-0.0482066,-0.06873118,0.03899158,-0.047442846,-0.034516826,-0.03800461,-0.032943197,-0.06600416,-0.06258612,0.029143777,-0.029370952,-0.019297127,-0.04225497,-0.006668147,0.010420973,0.026378492,0.07836125,-0.006375822,0.015335654,-0.017063653,-0.059017416,0.052894965,-0.08578675,0.05552466,-0.019056221,-7.0386555e-08,-0.014460382,0.0005324579,-0.01811414,0.084698625,0.04534107,0.004530717,-0.04897719,-0.01344052,-0.008039733,-0.040751267,0.061117537,-0.062653646,-0.040158138,0.02412634,0.017094113,0.026956059,0.012655491,0.0532214,-0.02154621,0.046513572,0.06953577,0.037765764,0.06322642,-0.033112586,0.10946618,-0.069180995,-0.011124921,0.09895366,-0.0030912352,-0.04194176,-0.04750847,-0.013720951,-0.00030263062,0.008910781,0.021565728,-0.04102007,0.098957755,-0.049638104,-0.017180381,0.0031176095,0.036657177,0.052498017,-0.057813227,0.074282184,0.009350984,-0.022571433,0.018602261,-0.026345827,0.012311603,0.064545,-0.01452753,-0.07247434,0.08392379,0.04657955,-0.0052912175,-0.0073016738,-0.014339487,0.011652093,-0.0030951449,0.00045807645,0.050187513,-0.024016894,-0.083461575,0.017639961]'),\n",
       " (' communication. I handled the project end-to-end - from extracting data from client databases, to creating and scheduling Boosting (LightGBM) models in Airflow, and delivering results back to the client’s systems. Models were updated monthly. \\n\\nI investigated each data source to identify key factors driving engagement and worked closely with a business analyst and project manager to align the solution with business goals. \\nThe results from all models were combined into one system to provide personalized recommendations for each channel over the next three months. It created a table with communication suggestions for every individual.\\n\\n',\n",
       "  'basic_info.md',\n",
       "  1,\n",
       "  462,\n",
       "  575,\n",
       "  113,\n",
       "  '[0.036393657,-0.047215153,-0.007821554,0.07464205,0.03889256,-0.008870791,0.06886233,0.031571493,-0.040778313,-0.040984724,-0.05685609,0.020541484,0.03733717,0.00073281315,0.046757407,0.09583448,0.07611109,-0.13633762,-0.033627044,-0.11217244,-0.044388562,-0.037729163,-0.010460121,0.0083239,-0.028603932,0.01593931,0.053396303,0.01957111,-0.025811436,0.009350876,0.012917935,0.06360359,0.07104562,0.05033748,-0.06486839,-0.008941625,0.010788413,0.009743943,-0.05741459,-0.0060866275,-0.077777326,-0.07418235,0.021361388,0.023020696,0.025865138,-0.07717784,0.023798365,0.010137784,-0.07234032,0.052928954,-0.11813371,-0.07219158,-0.013122293,0.08105334,0.011272778,0.042545892,-0.002672935,0.011358344,0.046713307,-0.048492033,-0.053248137,-0.015070577,-0.06369835,-0.0011402608,-0.0052414243,0.048644,-0.047840532,0.079179876,-0.0012271851,-0.015223417,-0.014741346,-0.038503267,-0.052949235,-0.013987241,0.002068133,0.029884055,0.01695658,0.0055439463,0.037798587,-0.0083523,-0.010485744,0.0069785435,-0.087318145,0.042988524,0.027371619,-0.06831621,0.010529766,0.032436505,-0.04873131,0.014121556,-0.072576754,0.023237435,0.026124902,-0.02924792,-0.05534003,0.049208004,-0.030637726,-0.10788228,-0.0036569154,0.034899697,-0.023215625,0.042272992,0.028042827,-0.031185122,-0.06915341,-0.05381932,0.019306185,0.090835094,0.018729743,0.011006435,-0.07803982,0.020497147,-0.012092216,-0.08609705,0.03690067,0.0053734705,-0.02900883,0.00029688867,-0.018622212,0.092666134,-0.031392265,0.027971376,0.1094713,-0.0023092628,-0.014205727,0.03167308,-0.026634086,4.7410027e-33,-0.03714729,0.023366863,0.008597384,0.06481545,0.07116676,-0.036828417,0.04880756,0.030846449,0.019239169,-0.03981903,-0.05149844,0.14247039,0.002970177,0.050627757,0.060469743,-0.0701712,-0.09420799,0.10874831,-0.04068377,-0.002779326,-0.0037157915,-0.085457265,-0.018911391,0.011971509,0.11961879,-0.009836979,0.08657155,0.057797763,0.07976079,0.0027297374,0.037504595,0.009558292,0.017341914,-0.06624555,-0.032644957,0.026883475,-0.052969392,-0.06769483,0.06673765,0.013177242,-0.025354512,0.02501396,-0.051995166,-0.022476384,-0.09823268,0.09679425,0.009313631,-0.032506347,-0.06308195,-0.0076725483,0.018824395,0.003340423,0.03156217,0.12239279,0.0006233642,-0.019359643,0.012480111,-0.053933404,0.066315345,0.011655401,-0.024118854,-0.0050012884,0.0020663508,-0.037266456,0.018895311,0.054930475,0.05169137,0.07915734,0.020500915,-0.045511406,-0.035257377,0.002615047,0.05457686,-0.06514602,0.029006654,-0.034217533,-0.04945329,-0.022013575,-0.04216273,0.0012492582,-0.015669601,0.012104956,0.04910014,-0.02967236,0.010393639,-0.004069468,-0.015202298,-0.030246401,-0.14989741,0.07642922,-0.045825206,0.082100354,-0.013889297,0.11796973,0.033397302,-3.5513947e-33,-0.06540867,-0.017933115,-0.059514612,0.059624176,0.11169163,-0.055600125,-0.06286874,-0.08030452,0.061413024,0.07447845,-0.023267873,-0.078852065,-0.0012568934,-0.0075208168,-0.0032597086,-0.078493915,0.038829394,-0.08104451,-0.0024091136,-0.0038306075,-0.025063334,0.04489087,-0.113573425,-0.093175426,-0.05533497,0.0958492,-0.0022214435,0.029591095,0.017907524,-0.011260778,-0.023900347,0.005605228,-0.021528011,-0.070928045,-0.00015163851,0.031246359,-0.04433194,-0.0066037243,-0.017601902,0.08582387,0.089517735,-0.019263415,-0.06762863,-0.008407642,-0.026093971,0.053636502,-0.009431117,-0.06297705,-0.051724896,-0.07578041,0.0030648436,-0.0035193744,-0.06369706,-0.0022287495,0.008995482,0.024840595,0.095286965,-0.027217172,0.047210205,-0.0004799629,-0.019864954,-0.033337105,0.113509215,-0.035317328,-0.0021124154,-0.0047175917,0.11286924,-0.034215923,-0.0077270726,0.0214847,0.008715881,0.0017732488,-0.009400182,0.115193605,0.00976988,0.0047559906,-0.03332579,-0.020364787,-0.040609878,-0.016259762,-0.072627716,0.065360054,0.018096825,-0.014581054,0.0058424417,0.005080013,0.009220116,-0.021922525,-0.04053564,-0.028449986,-0.06677167,-0.019518487,-0.079096556,0.032553945,-0.0035922464,-5.259346e-08,-0.10016785,0.006406633,0.04426196,0.039993692,-0.0040851496,-0.040180776,-0.011750988,0.096703075,0.06352453,-0.020552892,0.13588575,-0.05987399,-0.017108815,0.09200557,0.080809824,-0.039417665,0.052079592,-0.011547592,-0.044583328,-0.044827927,0.045643613,0.07284734,0.037326086,0.009754978,0.1007985,0.029297417,0.016366832,0.11313002,0.037685078,-0.0039403182,-0.015694661,0.017564941,-0.005119386,-0.02136389,-0.01961343,-0.02545536,-0.004331249,-0.013333403,-0.010288345,0.075897045,-0.011387315,0.06820792,-0.08785839,0.021853907,0.020857451,0.03631507,-0.052316707,-0.045959145,-0.051589604,0.03284243,-0.027926115,-0.04110018,0.02864579,0.06180391,0.061444554,-0.02964126,-0.028883923,-0.01828185,0.051222842,0.0025929974,-0.037950777,-0.037390023,-0.13287015,0.10080354]')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding_str = f\"[{','.join(map(str, query_embedding))}]\"\n",
    "\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            content, source, chunk_id, \n",
    "            start_token, end_token, token_count, embedding\n",
    "        FROM documents\n",
    "    \"\"\", (query_embedding_str))\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94d563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ce41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d039340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant information found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = query_rag(\n",
    "    #question=\"Any information on  recommendation systems?\",\n",
    "    question=\"Any information on  recommendation systems?\",\n",
    "    text_processor=text_processor,\n",
    "    hf_client=hf_client,\n",
    "    db_client=db_client,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d936d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Question: What is mario's email?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n",
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "No relevant information found.\n",
      "\n",
      "Sources (0 chunks):\n",
      "\n",
      " Question: How long does shipping take?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "No relevant information found.\n",
      "\n",
      "Sources (0 chunks):\n",
      "\n",
      " Question: Where there any projects with recommendation systems done by Mario?\n",
      "\n",
      "Answer:\n",
      "No relevant information found.\n",
      "\n",
      "Sources (0 chunks):\n",
      "\n",
      " Question: Does mario like data science?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "No relevant information found.\n",
      "\n",
      "Sources (0 chunks):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n Question: {question}\")\n",
    "    \n",
    "    result = query_rag(\n",
    "        question=question,\n",
    "        text_processor=text_processor,\n",
    "        hf_client=hf_client,\n",
    "        db_client=db_client,\n",
    "        k=5\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "    print(f\"\\nSources ({result['num_chunks']} chunks):\")\n",
    "    for src in result['sources']:\n",
    "        print(\n",
    "            f\"  - {src['source']} (chunk {src['chunk_id']}, \"\n",
    "            f\"tokens {src['start_token']}-{src['end_token']}, \"\n",
    "            f\"score {src['similarity']})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347aeefc",
   "metadata": {},
   "source": [
    "## Debug search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a24b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Vector distance (identical): 0.0000 (should be 0.0)\n",
      "INFO:__main__:Vector distance (different): 0.0254 (should be > 0)\n",
      "INFO:__main__:Vector index exists: idx_embedding\n"
     ]
    }
   ],
   "source": [
    "# def test_vector_operations(db_client):\n",
    "\"\"\"Test if pgvector operators work.\"\"\"\n",
    "\n",
    "with db_client.conn.cursor() as cur:\n",
    "    # Test 1: Create dummy vectors\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            ARRAY[1.0, 2.0, 3.0]::vector <=> ARRAY[1.0, 2.0, 3.0]::vector AS identical,\n",
    "            ARRAY[1.0, 2.0, 3.0]::vector <=> ARRAY[4.0, 5.0, 6.0]::vector AS different\n",
    "    \"\"\")\n",
    "    identical, different = cur.fetchone()\n",
    "    \n",
    "    logger.info(f\"Vector distance (identical): {identical:.4f} (should be 0.0)\")\n",
    "    logger.info(f\"Vector distance (different): {different:.4f} (should be > 0)\")\n",
    "    \n",
    "    # Test 2: Check if index exists\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT indexname, indexdef \n",
    "        FROM pg_indexes \n",
    "        WHERE tablename = 'documents' AND indexname = 'idx_embedding'\n",
    "    \"\"\")\n",
    "    index = cur.fetchone()\n",
    "    if index:\n",
    "        logger.info(f\"Vector index exists: {index[0]}\")\n",
    "    else:\n",
    "        logger.warning(\"Vector index not found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0f990c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Testing raw search for: 'This is a document with CV summary'\n",
      "INFO:__main__:================================================================================\n",
      "INFO:hf_client:Generated 1 embeddings\n",
      "INFO:__main__:Query embedding generated: 384 dimensions\n",
      "INFO:__main__:Sample values: [-0.07514718919992447, 0.1503158062696457, -0.06211642175912857, 0.020352579653263092, 0.053853780031204224]\n",
      "ERROR:__main__:No results returned at all!\n"
     ]
    }
   ],
   "source": [
    "# def test_raw_search(db_client, hf_client, question=\"email\"):\n",
    "# \"\"\"Test search with NO filtering.\"\"\"\n",
    "\n",
    "question= \"This is a document with CV summary\" #\"email\"\n",
    "\n",
    "logger.info(f\"Testing raw search for: '{question}'\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "# Generate embedding\n",
    "query_embedding = hf_client.get_embeddings([question])[0]\n",
    "if not isinstance(query_embedding, list):\n",
    "    query_embedding = query_embedding.tolist()\n",
    "\n",
    "logger.info(f\"Query embedding generated: {len(query_embedding)} dimensions\")\n",
    "logger.info(f\"Sample values: {query_embedding[:5]}\")\n",
    "\n",
    "# Search without ANY threshold\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            id,\n",
    "            source,\n",
    "            LEFT(content, 100) as preview,\n",
    "            1 - (embedding <=> %s::vector) AS similarity\n",
    "        FROM documents\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT 5\n",
    "    \"\"\", (query_embedding, query_embedding))\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "\n",
    "if not results:\n",
    "    logger.error(\"No results returned at all!\")\n",
    "    # return\n",
    "else:\n",
    "    logger.info(f\"Found {len(results)} results:\")\n",
    "    for i, (doc_id, source, preview, sim) in enumerate(results, 1):\n",
    "        logger.info(f\"{i}. Similarity: {sim:.4f}\")\n",
    "        logger.info(f\"   Source: {source} (ID: {doc_id})\")\n",
    "        logger.info(f\"   Preview: {preview}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7dbea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Stored content: Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened ...\n",
      "INFO:__main__:Stored embedding type: <class 'str'>\n",
      "INFO:__main__:Stored embedding sample: [-0.0\n",
      "INFO:hf_client:Generated 1 embeddings\n",
      "INFO:__main__:New embedding type: <class 'list'>\n",
      "INFO:__main__:New embedding sample: [-0.04964632913470268, 0.007881461642682552, 0.06498601287603378, 0.02755117043852806, 0.05388107895851135]\n",
      "INFO:__main__:Distance between stored and regenerated: 0.000000\n",
      "INFO:__main__:Similarity score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Get actual text from database\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT content, embedding FROM documents WHERE id = 1\")\n",
    "    stored_content, stored_embedding = cur.fetchone()\n",
    "\n",
    "logger.info(f\"Stored content: {stored_content[:100]}...\")\n",
    "logger.info(f\"Stored embedding type: {type(stored_embedding)}\")\n",
    "logger.info(f\"Stored embedding sample: {stored_embedding[:5]}\")\n",
    "\n",
    "# Generate NEW embedding for same text\n",
    "new_embedding = hf_client.get_embeddings([stored_content])[0]\n",
    "if not isinstance(new_embedding, list):\n",
    "    new_embedding = new_embedding.tolist()\n",
    "\n",
    "logger.info(f\"New embedding type: {type(new_embedding)}\")\n",
    "logger.info(f\"New embedding sample: {new_embedding[:5]}\")\n",
    "\n",
    "# Compare them\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT embedding <=> %s::vector AS distance\n",
    "        FROM documents \n",
    "        WHERE id = 1\n",
    "    \"\"\", (new_embedding,))\n",
    "    \n",
    "    distance = cur.fetchone()[0]\n",
    "    logger.info(f\"Distance between stored and regenerated: {distance:.6f}\")\n",
    "    logger.info(f\"Similarity score: {1 - distance:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d42308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Column name: embedding\n",
      "INFO:__main__:Data type: USER-DEFINED\n",
      "INFO:__main__:UDT name: vector\n"
     ]
    }
   ],
   "source": [
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT column_name, data_type, udt_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = 'documents' AND column_name = 'embedding'\n",
    "    \"\"\")\n",
    "    \n",
    "    col_info = cur.fetchone()\n",
    "    logger.info(f\"Column name: {col_info[0]}\")\n",
    "    logger.info(f\"Data type: {col_info[1]}\")\n",
    "    logger.info(f\"UDT name: {col_info[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431952a",
   "metadata": {},
   "source": [
    "## Insert text v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07eb81d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 3\n"
     ]
    }
   ],
   "source": [
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT COUNT(*) FROM documents\")\n",
    "    print(f\"Total documents: {cur.fetchone()[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "691af6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with embeddings: 3\n"
     ]
    }
   ],
   "source": [
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT COUNT(*) FROM documents WHERE embedding IS NOT NULL\")\n",
    "    print(f\"Documents with embeddings: {cur.fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9392909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf_client:Generated 1 embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs: 3\n",
      "Sample content: Our refund policy allows returns within 35 days of purchase. Full refunds are provided for unopened \n",
      "Stored dim: 384, Expected: 384\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check data exists\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT COUNT(*) FROM documents\")\n",
    "    print(f\"Total docs: {cur.fetchone()[0]}\")\n",
    "    \n",
    "    cur.execute(\"SELECT content FROM documents LIMIT 1\")\n",
    "    row = cur.fetchone()\n",
    "    if row:\n",
    "        print(f\"Sample content: {row[0][:100]}\")\n",
    "\n",
    "# Test 2: Check embedding dimension (fixed)\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT vector_dims(embedding) FROM documents LIMIT 1\")\n",
    "    stored_dim = cur.fetchone()[0]\n",
    "    print(f\"Stored dim: {stored_dim}, Expected: {db_client.embedding_dim}\")\n",
    "\n",
    "# Test 3: Raw vector search (no threshold)\n",
    "query_embedding = hf_client.get_embeddings([\"recommendation systems\"])[0]\n",
    "if hasattr(query_embedding, 'tolist'):\n",
    "    query_embedding = query_embedding.tolist()\n",
    "\n",
    "query_embedding_str = f\"[{','.join(map(str, query_embedding))}]\"\n",
    "\n",
    "with db_client.conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT content, 1 - (embedding <=> %s::vector) AS similarity\n",
    "        FROM documents\n",
    "        ORDER BY embedding <=> %s::vector\n",
    "        LIMIT 5\n",
    "    \"\"\", (query_embedding_str, query_embedding_str))\n",
    "    \n",
    "    for content, sim in cur.fetchall():\n",
    "        print(f\"Similarity: {sim:.4f} | {content[:80]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4970a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
